{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33175793, 0.39199865, 0.4373132 ],\n",
       "       [0.18262435, 0.93461861, 0.70944532],\n",
       "       [0.22283466, 0.64417073, 0.47550337],\n",
       "       [0.79821745, 0.87565398, 0.68196597],\n",
       "       [0.01370657, 0.9784358 , 0.06622164],\n",
       "       [0.67507249, 0.47406148, 0.23010109],\n",
       "       [0.72714257, 0.34930401, 0.01073209],\n",
       "       [0.04354961, 0.43916842, 0.44082348],\n",
       "       [0.78048189, 0.82354847, 0.3143967 ],\n",
       "       [0.13272091, 0.2310466 , 0.91095381]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg.linalg import norm, inv, cholesky, solve, qr, lstsq\n",
    "from scipy.linalg import lu, eigvals\n",
    "from sklearn.preprocessing import normalize\n",
    "from time import process_time\n",
    "from math import inf\n",
    "\n",
    "n = 10; m = 8;\n",
    "data = np.random.rand(n,m); data = np.maximum(data, np.zeros((n,m)))\n",
    "k = np.int(np.floor(np.math.sqrt(np.max([n,m]))))\n",
    "W = np.random.rand(n,k)\n",
    "H = np.random.rand(k,m) \n",
    "\n",
    "maxiter = 200\n",
    "tol = 1e-6\n",
    "rho = 1e-3\n",
    "\n",
    "W = np.maximum(W, rho)\n",
    "H = np.maximum(H, rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_it(b, A):\n",
    "\n",
    "    # \n",
    "    # This is a supplemental function for function nmf_alt_lsq_as.  It's purpose is to solve\n",
    "    # Y = WH for W when given Y, H or for H when given Y, W.\n",
    "    # \n",
    "    # Input:\n",
    "    #     b = a numpy array size n-by-m, the RHS in AX = b\n",
    "    #     A = a numpy array size n-by-k or k-by-m, the constant of the LHS of AX = b\n",
    "    #\n",
    "    # Output:\n",
    "    #     X = a numpy array, either W or H\n",
    "    #\n",
    "\n",
    "    # SPD check: if eigenvalues are negative or imaginary, we initialize matrix differently\n",
    "    AAT = A.T @ A\n",
    "    if any(np.isreal(eigvals(AAT))) or any(eigvals(AAT) <= 0) :\n",
    "\n",
    "        new_vals = np.random.randint(low = 1, high = 100, size = AAT.shape[0])\n",
    "        q,_ = qr(AAT)\n",
    "        AAT = q.T @ np.diag(new_vals) @ q\n",
    "        AAT = np.maximum(AAT, rho)\n",
    "\n",
    "    r = b.shape[1]\n",
    "    R = cholesky(AAT)\n",
    "    D = solve(R.T, (A.T @ b))\n",
    "    X = np.zeros((k, r)); \n",
    "    # initialize x to be random, nonnegative vector\n",
    "    temp = np.random.rand(k, 1)\n",
    "    seq = [i for i in range(r)]\n",
    "\n",
    "    # finds the NMF for d = R*x, one column of X at a time\n",
    "    temp = lsqnoneg(R, D[:, seq[0]], temp)\n",
    "    X[:, seq[0]] = temp.reshape((3,))\n",
    "    for i in range(1, r):\n",
    "        temp = lsqnoneg(R, D[:, seq[i]], temp)\n",
    "        X[:, seq[i]] = temp.reshape((3,))\n",
    "    \n",
    "    # return W or H \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsqnoneg(C, d, x):\n",
    "\n",
    "    # \n",
    "    # This is a supplemental function for function nmf_alt_lsq_as.  It's purpose is to solve the\n",
    "    # convex problem min_x{||d - Cx||_f^2} using the active set strategy described in \n",
    "    #\n",
    "    # Gu, R., Du, Q., & Billinge, S. J. (2021). A fast two-stage algorithm for non-negative matrix \n",
    "    # factorization in streaming data. arXiv preprint arXiv:2101.08431.\n",
    "    #\n",
    "    # is used here.\n",
    "    # \n",
    "    # Input:\n",
    "    #     C = a numpy array found from a Cholesky factorization, a constant\n",
    "    #     d = a numpy array, also a constant\n",
    "    #     x = a numpy array, to be determined in the run of this function\n",
    "    #     nZeroes = a dummy variable\n",
    "    #\n",
    "    # Output:\n",
    "    #     z = a numpy array, determined in the run of this function\n",
    "    #\n",
    "\n",
    "    d = d.reshape((k,1))\n",
    "\n",
    "    Z = x <= tol; indx_Z = Z.tolist(); Z = [elem[0] for elem in indx_Z]\n",
    "    P = x > tol; indx_P = P.tolist(); P = [elem[0] for elem in indx_P]\n",
    "    wz = np.zeros((k, 1)); \n",
    "    z = np.zeros((k, 1)); g, _, _, _ = lstsq(C[:,P], d, rcond = None); z[P] = g;\n",
    "        \n",
    "    for outiter in range(20):\n",
    "        for inneriter in range(10):\n",
    "            \n",
    "            indx = z <= 0; indx = [elem[0] for elem in indx]; Q = indx and P\n",
    "\n",
    "            if x[Q].size == 0:\n",
    "                alpha = rho\n",
    "            else:\n",
    "                alpha = np.min(x[Q]/(x[Q] - z[Q] + rho))\n",
    "                \n",
    "            x = x + alpha*(z - x)\n",
    "            indx = np.abs(x) < tol; indx = [elem[0] for elem in indx]; Z = (indx and P) or Z\n",
    "            P = x > tol; indx = P.tolist(); P = [elem[0] for elem in indx]\n",
    "            z = np.zeros((k, 1)); g, _, _, _ = lstsq(C[:,P], d, rcond = None); z[P] = g\n",
    "\n",
    "        x = np.array(z); w = C.T @ (d - C @ x)\n",
    "        indx = w[Z] > tol; indx = [elem[0] for elem in indx]\n",
    "\n",
    "        z = np.zeros((k, 1)); \n",
    "        wz[P] = -inf; \n",
    "        if (np.sum(Z) >  0):\n",
    "            wz[Z] = w[Z]\n",
    "        \n",
    "        t = np.argmax(wz); P[t] = True; Z[t] = False;\n",
    "        g, _, _, _ = lstsq(C[:,P], d, rcond = None); z[P] = g\n",
    "            \n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1\n",
    "\n",
    "Stage 1 is the least squares step with active set method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmf_alt_lsq_as(Y, W, H):\n",
    "\n",
    "    # grad_W = ((W @ H) - Y) @ H.T\n",
    "    # grad_H = W.T @ ((W @ H) - Y)\n",
    "\n",
    "    flag = 0\n",
    "    # iter = 0\n",
    "\n",
    "    for iter in range(maxiter):\n",
    "\n",
    "        W = get_it(Y.T, H.T); W = W.T\n",
    "        H = get_it(Y, W)\n",
    "\n",
    "        # normalize\n",
    "        W = normalize(W, axis = 0)\n",
    "        H = normalize(H, axis = 1)\n",
    "\n",
    "        #update gradients\n",
    "        # grad_W = ((W @ H) - Y) @ H.T\n",
    "        # grad_H = W.T @ ((W @ H) - Y)\n",
    "\n",
    "        # checking for ??\n",
    "        # sigma ??\n",
    "        if ( (iter > 1 and np.sum(W > 0) == n*k) and (np.sum(H > 0) == k*m) or iter == 50 ):\n",
    "\n",
    "            flag = flag + 1\n",
    "\n",
    "            if flag == 2:\n",
    "                break;\n",
    "        else:\n",
    "\n",
    "            flag = 0\n",
    "\n",
    "    return [W, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when run after the other functions are compiled, this method took 1m 7.3s.\n",
    "[W, H] = nmf_alt_lsq_as(data, W, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2\n",
    "Stage 2 is the interior precorrector method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmf_int_precor(data, W, H):\n",
    "\n",
    "    # initiate eta\n",
    "    eta = 0\n",
    "\n",
    "    # initiate r and s\n",
    "    grad_W = ((W @ H) - data) @ H.T\n",
    "    grad_H = W.T @ ((W @ H) - data)\n",
    "    r = np.ones((k*n, 1))*np.max(np.abs(grad_W))\n",
    "    s = np.ones((k*m, 1))*np.max(np.abs(grad_H))\n",
    "\n",
    "    # initiate mu and sigma\n",
    "    mu = inf\n",
    "    sigma = inf\n",
    "\n",
    "    for i in range(maxiter):\n",
    "\n",
    "        # set up for tolerance check of E(w_k, h_k, r_k, s_k) in algorithm 2\n",
    "        grad_W = ((W @ H) - data) @ H.T; gra_W = grad_W.reshape((k*n, 1));\n",
    "        grad_H = W.T @ ((W @ H) - data); gra_H = grad_H.reshape((k*m, 1))\n",
    "        w = W.reshape((k*n, 1)); h = H.reshape((k*m, 1))\n",
    "\n",
    "        temp1 = np.vstack((gra_W - r,gra_H - s))\n",
    "        temp2 = np.vstack((w * r, h * s))\n",
    "\n",
    "        # tolerance check\n",
    "        if np.max([norm(temp1), norm(temp2)]) < tol:\n",
    "            break\n",
    "\n",
    "        # initiate mu, eta\n",
    "        mu = 0\n",
    "        nu = 0\n",
    "        eta = sigma < 1e-2\n",
    "\n",
    "        # Finding Q2 in equation (5)\n",
    "        if i == 0:\n",
    "            Q2 = np.zeros((k*m, k*m))\n",
    "\n",
    "        for j in range(m):\n",
    "            \n",
    "            indx = np.r_[j*k:(j*k+k)]\n",
    "            values = s[indx]/(h[indx] + rho); D = np.diagflat(values)\n",
    "            Q2[j*k:(j*k+k), j*k:(j*k+k)] = (W.T @ W) + D\n",
    "\n",
    "        # Finding CP in equation (?)\n",
    "        if i == 0:\n",
    "            CP1i = np.zeros((m*k, n*k)); Ri = np.zeros((n*k, k)); Rit = Ri;\n",
    "\n",
    "        Rx = r/(w + rho)\n",
    "\n",
    "        for j in range(n):\n",
    "            \n",
    "            indx = np.r_[j*k:(j*k+k)]\n",
    "            values = Rx[indx] + rho; D = np.diagflat(values)\n",
    "            Q1 = inv(cholesky( (H @ H.T) + D ))\n",
    "\n",
    "            Ri[indx,:] = Q1; Rit[indx,:] = Q1.T\n",
    "            temp1 = W[j,:].reshape((1,k)); \n",
    "            temp2 = ((Q1.T.reshape((k*k,1))) @ (eta*(W @ H - data)[j,:].reshape((1,m)))).reshape((k,m*k))\n",
    "            F = np.tile(temp1.T, (m, k)) * np.tile((Q1.T @ H), (k, 1)).T.reshape((k, k*m)).T + temp2.T\n",
    "            CP1i[:, indx] = F\n",
    "\n",
    "\n",
    "        # prediction step\n",
    "        \n",
    "        beq1 = -gra_W\n",
    "        beq2 = -gra_H\n",
    "        reshape_beq1 = (np.tile(beq1.reshape((k, n)), (k, 1))).reshape((k, k*n)).T\n",
    "        P1ib1 = np.sum(Ri * (reshape_beq1), axis = 1)\n",
    "        [P, L, U] = lu(Q2 - (CP1i @ CP1i.T))\n",
    "        CP = (CP1i @ P1ib1).reshape((k*m, 1))\n",
    "        g, _, _, _ = lstsq(beq2 - CP, L, rcond = None)\n",
    "        solu2, _, _, _ = lstsq(g.T, U, rcond = None); solu2 = solu2.T\n",
    "        reshape_diff = np.tile(P1ib1.reshape((n*k, 1)) - (CP1i.T @ solu2), (1, k))\n",
    "        solu1 = np.sum((Ri * reshape_diff), axis = 1); solu1 = solu1.reshape((n*k, 1))\n",
    "        dr = ((mu/w) - r) - (r * solu1/w)\n",
    "        ds = ((nu/h) - s) - (s * solu2/h)\n",
    "\n",
    "        solutions = -np.vstack([solu1, solu2])/np.vstack([w, h])\n",
    "        derivs = -np.vstack([dr, ds])/np.vstack([r, s])\n",
    "        step1 = np.min([1/np.max(solutions), 1])\n",
    "        step2 = np.min([1/np.max(derivs), 1])\n",
    "        mu_aff = ( (np.vstack([w, h]) + step1*np.vstack([w,h])).T @ (np.vstack([r,s]) + step2*np.vstack([dr,ds])))/(n*k + m*k)\n",
    "        mu = (np.vstack([w,h]).T @ np.vstack([r,s]))/(n*k + m*k)\n",
    "        sigma = np.min([((mu_aff/mu)**3), 0.99])\n",
    "\n",
    "        aff_1 = solu1 * dr; aff_2 = solu2 * ds;\n",
    "\n",
    "        beq1 = (mu*sigma - aff_1)/(w - gra_W);\n",
    "        beq2 = (mu*sigma - aff_2)/(h - gra_H);\n",
    "\n",
    "        reshape_beq1 = (np.tile(beq1.reshape((k, n)), (k, 1))).reshape((k, k*n)).T\n",
    "        P1ib1 = np.sum(Ri * (reshape_beq1), axis = 1)\n",
    "        [P, L, U] = lu(Q2 - (CP1i @ CP1i.T))\n",
    "        CP = (CP1i @ P1ib1).reshape((k*m, 1))\n",
    "        g, _, _, _ = lstsq(beq2 - CP, L, rcond = None)\n",
    "        solu2, _, _, _ = lstsq(g.T, U, rcond = None); solu2 = solu2.T\n",
    "        reshape_diff = np.tile(P1ib1.reshape((n*k, 1)) - (CP1i.T @ solu2), (1, k))\n",
    "        solu1 = np.sum((Ri * reshape_diff), axis = 1); solu1 = solu1.reshape((n*k, 1))\n",
    "        dr = ((mu/w) - r) - (r * solu1/w)\n",
    "        ds = ((nu/h) - s) - (s * solu2/h)\n",
    "\n",
    "        # update step-sizes\n",
    "        solutions = -np.vstack([solu1, solu2])/np.vstack([w, h])\n",
    "        derivs = -np.vstack([dr, ds])/np.vstack([r, s])\n",
    "        step1 = np.min([0.9/np.max(solutions), 1])\n",
    "        step2 = np.min([0.9/np.max(derivs), 1])\n",
    "\n",
    "        # update the gradients for W and H\n",
    "        dW = solu1.reshape((k,n)).T\n",
    "        dH = solu2.reshape((k,m))\n",
    "\n",
    "        # update W, H, r, and s using gradient update\n",
    "        W1 = W + dW*step1\n",
    "        H1 = H + dH*step1\n",
    "        r1 = r + dr*step2\n",
    "        s1 = s + ds*step2\n",
    "\n",
    "        # calculate phi(W, H)\n",
    "        logW = np.log(W); logH = np.log(H)\n",
    "        phi = (0.5)*(norm(W @ H - data, ord = 'fro')) - mu*sigma*np.sum(logW, axis = None) - mu*sigma*np.sum(logH, axis = None)\n",
    "\n",
    "        # calculate grad_phi(W,H)\n",
    "        grad_phi = np.vstack([1/(gra_W - mu*sigma*w), 1/(gra_H - mu*sigma*h)])\n",
    "\n",
    "        d0 = np.vstack([dW.reshape((k*n, 1)), dH.reshape((k*m, 1))])\n",
    "        if ((grad_phi.T @ d0) >= 0):\n",
    "            continue\n",
    "\n",
    "        W = np.maximum(W1, rho)\n",
    "        H = np.maximum(H1, rho)\n",
    "        r = r1 \n",
    "        s = s1\n",
    "\n",
    "    return [W, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "[W, H] = nmf_int_precor(data, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6980688653616256"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(W @ H - data, ord = 'fro')/norm(data, ord = 'fro')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2784cf6f491f9589cee5dc97f3b2ddcd67774395fd802181d4f26fbd1f0627e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
